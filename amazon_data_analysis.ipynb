{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websites such as Amazon contain large numbers of product reviews.  This presents a rich source of information that we can use to understand more about these products, as well as how people communicate positive and negative sentiments more generally.\n",
    "\n",
    "The dataset comprising reviews of more than 1000 products.\n",
    "\n",
    "The dataset is a CSV file containing a number of fields:\n",
    "\n",
    "ID: Indicates a unique ID number for each product in the dataset\n",
    "product_name: The name of the product, as displayed on the Amazon website\n",
    "category: Each product is assigned to a single category indicating the type of product\n",
    "noRatings: This represents the number of positive or negative ratings (not reviews) of the product\n",
    "cost: How much the product sells for.  Note that many products have a price range rather than a single price, typically meaning they can be customized when purchased.\n",
    "REVIEWLIST: A list of reviews for the product, expressed as a JSON string\n",
    "product_url: A link to the product's page on Amazon\n",
    "\n",
    "Note that there are some data integrity issues present in the file.  For example, some products are missing reviews and others are missing prices.\n",
    "\n",
    "Using this dataset, you will have an opportunity to learn how to identify positive and negative sentiments by analysing the linguistic patterns in the reviews."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Loading data\n",
    "\n",
    "Implement the function task1() in task1.py that outputs a json file called task1.json in the following format:\n",
    "{\"Number of Products:\": X, \"Number of Categories:\": Y}\n",
    "where X and Y  are the number of products and number of categories respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def task1():\n",
    "\n",
    "    dataset = pd.read_csv(r'/course/data/dataset.csv')\n",
    "    task1_df = pd.DataFrame(dataset, columns = ['ID', 'category'])\n",
    "\n",
    "    df = task1_df.groupby('category')['ID'].nunique()\n",
    "    num_category = int(df.count()) \n",
    "    num_product = int(task1_df.count()[1])\n",
    "\n",
    "    json_dict = {\"Number of Products:\": num_product, \"Number of Categories:\": num_category}\n",
    "    task1_json = json.dumps(json_dict)\n",
    "    json.dump(json.loads(task1_json), open(\"task1.json\", \"w\"))\n",
    "\n",
    "    return 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Data aggregation\n",
    "\n",
    "Each review contains a review_star field allowing you to determine how many stars (out of a possible 5) the review rated the product.  For example, a 5 star review contains the following:\n",
    "\n",
    "\"review_star\": \"a-icon a-icon-star a-star-5 review-rating\"\n",
    "\n",
    "Implement the function task2() in task2.py which determines the average review score for each product.  Any review with a missing or invalid review_star field should not be included in the calculation. \n",
    "\n",
    "If a product contains no valid reviews, you should assign it an average score of 0 or None.\n",
    "\n",
    "Your function should save its output to a csv file called task2.csv, which contains the following headings: ID,  category, average_score. Each row in the file should contain the details of one product, with\n",
    "\n",
    "ID and category containing the original values in the data file.\n",
    "\n",
    "average_score being the average review score for each product\n",
    "\n",
    "The rows in task2.csv should be in ascending order of ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "\n",
    "def findscore(text):\n",
    "    score = 0\n",
    "    for char in text:\n",
    "        if char.isdigit():\n",
    "            score += int(char)\n",
    "    return score\n",
    "\n",
    "def task2():\n",
    "   \n",
    "    dataset = pd.read_csv(r'/course/data/dataset.csv')\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns = ['ID', 'category','REVIEWLIST'])\n",
    "    ID = df['ID']\n",
    "    category = df['category']\n",
    "    review = df['REVIEWLIST']\n",
    "\n",
    "    # access the review and convert it into python dict\n",
    "    result_lst = []\n",
    "    for i in range(len(ID)):\n",
    "        score = 0\n",
    "        rating = review[i]\n",
    "        rating_dict = json.loads(rating)\n",
    "\n",
    "        # access the review star and add it to the score variable    \n",
    "        for j in range(len(rating_dict)):\n",
    "            star_review = rating_dict[j]['review_star']      \n",
    "            score += findscore(star_review)\n",
    "\n",
    "        if len(rating_dict) == 0:\n",
    "            result_lst.append([i, category[i], 0])\n",
    "        else:\n",
    "            result_lst.append([i,category[i],round(score/len(rating_dict), 2)])\n",
    "\n",
    "    # generate csv\n",
    "    header = ['ID', 'category', 'average_score' ]\n",
    "    with open('task2.csv','w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for item in result_lst:\n",
    "            writer.writerow(item)\n",
    "            \n",
    "    return 0\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Calculating the average product price \n",
    "\n",
    "Each product comes with a cost field, which specifies the sale price of the item. The format of this field is not consistent - some products have a single cost whereas others have a price range.\n",
    "\n",
    "Implement the function task3() in task3.py that calculates the average cost for each product:\n",
    "\n",
    "If a product contains only a single price, that price should be the average cost.\n",
    "If a product contains a price range (e.g. $X - $Y), then the average cost should be (X+Y)/2\n",
    "If a product contains an invalid or missing price, then average cost should be zero.\n",
    "\n",
    "All average costs should be listed as a single numeric figure, rounded to two decimal places, with no dollar signs present.\n",
    "\n",
    "Your function should save its output to a csv file called task3.csv, which contains the following headings: ID, category, average_cost. Each row in the file should contain the details of one product, with\n",
    "\n",
    "ID and category containing the original values in the data file.\n",
    "\n",
    "average_cost being the average cost as determined above.\n",
    "\n",
    "The rows in task3.csv should be in ascending order of ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from re import sub\n",
    "\n",
    "def task3():\n",
    "    dataset = pd.read_csv(r'/course/data/dataset.csv')\n",
    "\n",
    "    df = pd.DataFrame(dataset)\n",
    "    ID = df['ID']\n",
    "    category = df['category']\n",
    "    cost = df['cost']\n",
    "    \n",
    "    average_cost = []\n",
    "    for i in range(len(ID)):\n",
    "        sub(',', '', cost[i])\n",
    "        if '$' in cost[i]:\n",
    "            if '-' in cost[i]:\n",
    "                price = cost[i].split('-')\n",
    "                price1 = float(sub(r'[^\\d.]', '', price[0]))\n",
    "                price2 = float(sub(r'[^\\d.]', '', price[1]))\n",
    "                ave = str(round(((price1 + price2) / 2), 2))\n",
    "                average_cost.append([i, category[i], '$'+ ave])\n",
    "            else:\n",
    "                average_cost.append([i, category[i], '$' + str(float(sub(r'[^\\d.]', '', cost[i])))])\n",
    "        else:\n",
    "            average_cost.append([i, category[i], '$0.00'])\n",
    "    \n",
    "\n",
    "    header = ['ID', 'category', 'average_cost' ]\n",
    "    with open('task3.csv','w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for item in average_cost:\n",
    "            writer.writerow(item)\n",
    "            \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Plotting the average review score\n",
    "\n",
    "For this task, consider only the 'Pet Supplies' category of products.\n",
    "\n",
    "Implement the function task4() in task4.py to generate a plot allowing you to compare the average price with the average review score for each product in 'Pet Supplies'.  Save your plot plot as task4.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv  \n",
    "\n",
    "def remove_char(list, char):\n",
    "    for i in range(0,len(list)):\n",
    "        list[i] = list[i].replace(char,'')\n",
    "    return list\n",
    "\n",
    "def task4():\n",
    "    task2_data = pd.read_csv(r'task2.csv')\n",
    "    task3_data = pd.read_csv(r'task3.csv')\n",
    "\n",
    "    petsupplies_avgprice = []\n",
    "    petsupplies_avgscore = []\n",
    "    for i in range(len(task3_data)):\n",
    "        task3 = task3_data.iloc[[i]].values[0]\n",
    "        task2 = task2_data.iloc[[i]].values[0]\n",
    "        if task3[1] == 'Pet Supplies':\n",
    "            petsupplies_avgprice.append(float(task3[2][1:]))\n",
    "        if task2[1] == 'Pet Supplies':\n",
    "            petsupplies_avgscore.append(task2[2])\n",
    "\n",
    "    plt.clf()    \n",
    "    task4_plot = plt.scatter(petsupplies_avgscore, petsupplies_avgprice)\n",
    "    plt.xlabel('Pet Supplies Average Score')\n",
    "    plt.ylabel('Pet Supplies Average Price')\n",
    "    plt.title('Average Price vs Average Review Score')\n",
    "    task4 = plt.savefig('task4.png')\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Comparing the review scores between categories\n",
    "\n",
    "Implement the function task5() in task5.py which outputs a file called task5.png comparing the means of the average review scores of products in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv \n",
    "\n",
    "def task5():\n",
    "    task2_data = pd.read_csv(r'task2.csv')\n",
    "    category = np.array(list(task2_data['category']))\n",
    "    category_data = np.unique(category)\n",
    "\n",
    "    avg_cat_score = list(round((task2_data.groupby('category')['average_score']).mean(), 2))\n",
    "    \n",
    "    # Plot the data\n",
    "    dt = sorted([[avg_cat_score[i], category_data[i]] for i in range(len(category_data))])\n",
    "    plt.clf()    \n",
    "    fig, task5_plot = plt.subplots(figsize =(25, 10))\n",
    "    task5_plot = plt.barh([i[1] for i in dt], [i[0] for i in dt])  \n",
    "\n",
    "    c = -1\n",
    "    for i in task5_plot.patches:\n",
    "        c += 1\n",
    "        plt.text(i.get_width()+0.02, i.get_y()+0.2, dt[c][0],\n",
    "             fontsize = 12, color ='red')\n",
    "\n",
    "    plt.title('Average Review Scores of Products in each Category', fontsize = 40)\n",
    "    plt.xlabel('Mean Average Score', fontsize = 20)\n",
    "    plt.ylabel('Categories',fontsize = 30)\n",
    "    \n",
    "    task5 = plt.savefig('task5.png')\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Text processing\n",
    "\n",
    "We would now like to develop a way of understanding whether a review is favourable or unfavourable towards a product, based on the text of the review.  To do this, we would like to consider each sequential pair of words in the product.  For example, intuitively if the sequence 'great product' appears in a review, we might conclude that the review is favourable to the product.  Building this type of system requires us to pre-process the text of the reviews.\n",
    "\n",
    "The text content of a review is in the JSON formatted REVIEWLIST field's review_body value.\n",
    "\n",
    "Implement the function task6() in task6.py that performs the following pre-processing steps on the content of the reviews:\n",
    "\n",
    "Convert all non-alphabetic characters (for example, numbers, apostrophes and punctuation), except for spacing characters (for example, whitespaces, tabs and newlines) to single-space characters. For example, ‘&’ should be converted to ‘ ’. You should consider non-English alphabetic characters as non-alphabetic for the purposes of this conversion.\n",
    "\n",
    "Convert all spacing characters such as tabs and newlines into single-space characters, and ensure that only one whitespace character exists between each token.\n",
    "\n",
    "Change all uppercase characters to lowercase.\n",
    "\n",
    "Remove all stop words in nltk’s list of English stop words from the review.\n",
    "\n",
    "Remove all remaining words that are only one or two characters long from the review.\n",
    "\n",
    "Generate each sequential pair of words that occur in the review (i.e. word bigrams without padding).  For example, the review 'great product great price' should generate the following list: ['great product', 'product great', 'great price']\n",
    "\n",
    "Once steps 1 -- 6 are done, build a JSON file representing each review in the dataset.  The JSON file should contain a list of objects.  Each object should represent one review and contain the following key/value pairs:\n",
    "\n",
    "score: containing the score for that review\n",
    "\n",
    "bigrams: containing the list of word bigrams appearing in the review as described above\n",
    "\n",
    "Any reviews that don't contain a valid score or contain no bigrams after pre-processing should be ignored.\n",
    "\n",
    "Your file should be saved as task6.json. \n",
    "\n",
    "The creation of vocabulary should be implemented reasonably efficiently.  The run time of task 6 should be no more than 45 seconds. Excessively long execution time for this task will result in a deduction of up to 2 marks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "\n",
    "def bigram(text):\n",
    "    return [f\"{word1} {word2}\" for word1, word2 in ngrams(text.split(), 2)]\n",
    "\n",
    "def task6():\n",
    "    task2_data = pd.read_csv(r'task2.csv')\n",
    "    dataset = pd.read_csv(r'/course/data/dataset.csv')\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns = ['ID', 'category','REVIEWLIST'])\n",
    "    ID = df['ID']\n",
    "    category = df['category']\n",
    "    review = df['REVIEWLIST']\n",
    "    score = task2_data['average_score']\n",
    "\n",
    "    stop_pattern = r'.(?!\\w)'\n",
    "    special_stop_pattern = r'\\.(?=\\w)'\n",
    "    no_punct_pattern = r'[^a-z\\s]'\n",
    "\n",
    "    task6_lst = []\n",
    "    for i in range(len(ID)):\n",
    "        review_dict = json.loads(review[i])\n",
    "        for j in range(len(review_dict)):\n",
    "             review_body = review_dict[j]['review_body']\n",
    "\n",
    "             # convert non-alphabetic character and spacing characters into single-space\n",
    "             review_body = re.sub('[^0-9a-zA-Z]+', ' ', review_body) \n",
    "             review_body = re.sub('\\d+', ' ', review_body)\n",
    "\n",
    "             # convert all uppercase characters to lowercase\n",
    "             review_body = review_body.lower()\n",
    "\n",
    "             # remove all stop words\n",
    "             stop_words = set(stopwords.words('english'))\n",
    "             review_body = ' '.join([i for i in review_body.split() if i not in stop_words])\n",
    "\n",
    "             # remove all remaining words that are only one or two characters long\n",
    "             one_two_char = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "             review_body = one_two_char.sub('', review_body)\n",
    "\n",
    "             # generate word bigrams\n",
    "             review_body_bigrams = bigram(review_body)\n",
    "\n",
    "        task6_lst.append((score[i], review_body_bigrams))\n",
    "    \n",
    "    task6_json = json.dumps(task6_lst)\n",
    "    json.dump(json.loads(task6_json), open(\"task6.json\", \"w\"))\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Detecting the most indicative bigrams of positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "import math\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "\n",
    "def findscore(text):\n",
    "    num = re.findall(r'\\d+', text)\n",
    "    for i in num:\n",
    "        return i\n",
    "\n",
    "def bigram(text):\n",
    "    return [f\"{word1} {word2}\" for word1, word2 in ngrams(text.split(), 2)]\n",
    "\n",
    "def process(text):\n",
    "    # convert non-alphabetic character and spacing characters into single-space\n",
    "    text = re.sub('[^0-9a-zA-Z]+', ' ', text) \n",
    "    text = re.sub('\\d+', ' ', text)\n",
    "\n",
    "    # convert all uppercase characters to lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove all stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    text = ' '.join([i for i in text.split() if i not in stop_words])\n",
    "\n",
    "    # remove all remaining words that are only one or two characters long\n",
    "    one_two_char = re.compile(r'\\W*\\b\\w{1,3}\\b')\n",
    "    text = one_two_char.sub('', text)\n",
    "\n",
    "    # generate word bigrams\n",
    "    text = bigram(text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def task7():\n",
    "    dataset = pd.read_csv(r'/course/data/dataset.csv')\n",
    "\n",
    "    df = pd.DataFrame(dataset, columns = ['ID', 'category','REVIEWLIST'])\n",
    "    \n",
    "    ID = df['ID']\n",
    "    category = df['category']\n",
    "    review = df['REVIEWLIST']\n",
    "\n",
    "    positive_review = {}\n",
    "    negative_review = {}\n",
    "    for i in range(len(ID)):\n",
    "        rating = review[i]\n",
    "        rating_dict = json.loads(rating)\n",
    "\n",
    "        if len(rating_dict)!= 0:\n",
    "            for j in range(len(rating_dict)):\n",
    "                star_review = rating_dict[j]['review_star']      \n",
    "                num = findscore(star_review)  \n",
    "                review_body = process(rating_dict[j]['review_body'])\n",
    "                if (type(num) == str):\n",
    "                    if len(review_body) == 0:\n",
    "                        continue\n",
    "                    if int(num) == 1:\n",
    "                        for bigram in review_body:\n",
    "                            if bigram in negative_review:\n",
    "                                negative_review[bigram] += 1\n",
    "                            else:\n",
    "                                negative_review[bigram] = 1\n",
    "                    elif int(num) == 5:\n",
    "                        for bigram in review_body:\n",
    "                            if bigram in positive_review:\n",
    "                                positive_review[bigram] += 1\n",
    "                            else:\n",
    "                                positive_review[bigram] = 1\n",
    "\n",
    "    # loop through each bigram and see what's the count is, then divide by the sum\n",
    "    total_pos = sum(positive_review.values()) \n",
    "    total_neg = sum(negative_review.values())\n",
    "\n",
    "    # put comment\n",
    "    # already exclude the odds of 0 or inf by separate it into two dictionary\n",
    "    for bigram in positive_review:\n",
    "        positive_review[bigram] = [positive_review[bigram]/total_pos, (positive_review[bigram]/total_pos)/(1 - positive_review[bigram]/total_pos)]\n",
    "    for bigram in negative_review:\n",
    "        negative_review[bigram] = [negative_review[bigram]/total_neg, (negative_review[bigram]/total_neg)/(1 - negative_review[bigram]/total_neg)]\n",
    "\n",
    "    odd_ratio_dict = {}\n",
    "    for bigram in negative_review:\n",
    "        if bigram in positive_review:\n",
    "            if positive_review[bigram] != 0:\n",
    "                odd_neg_ratio = positive_review[bigram][1]/negative_review[bigram][1]\n",
    "                odd_ratio_dict[bigram] = round(math.log10(odd_neg_ratio), 4)\n",
    "    for bigram in positive_review:\n",
    "        if bigram in negative_review:\n",
    "            if negative_review[bigram] != 0:\n",
    "                odd_pos_ratio = positive_review[bigram][1]/negative_review[bigram][1]\n",
    "                odd_ratio_dict[bigram] = round(math.log10(odd_pos_ratio), 4)\n",
    "    \n",
    "    # TASK 7a\n",
    "    task7a_data = dict(sorted(odd_ratio_dict.items(), key=lambda item: item[1]))\n",
    "    \n",
    "    header = ['bigram', 'log_odds_ratio' ]\n",
    "    with open('task7a.csv','w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(header)\n",
    "        for bigram in task7a_data.keys():\n",
    "            f.write(\"%s,%s\\n\"%(bigram, task7a_data[bigram]))\n",
    "\n",
    "    # TASK 7b\n",
    "    log_odds_ratio_data = odd_ratio_dict.values()\n",
    "    plt.clf()    \n",
    "    task7b_plot = plt.hist(log_odds_ratio_data, bins = 20)\n",
    "    plt.xlabel('Log odds ratio', fontsize = 30)\n",
    "    plt.ylabel('Frequency', fontsize = 30)\n",
    "    plt.title(\"Bigrams' log odds ratio and its Frequency\", fontsize = 40)\n",
    "    task7b = plt.savefig('task7b.png')\n",
    "\n",
    "    # TASK 7c\n",
    "    sorted_task7c_data = sorted(((value, key) for (key,value) in task7a_data.items()), reverse = True)\n",
    "    task7c_data = {k: v for v, k in sorted_task7c_data}\n",
    "    top10_bigram = list(task7c_data.keys())[0:10]\n",
    "    top10_bigram_logoddratio = list(task7c_data.values())[0:10]\n",
    "    last10_bigram = list(task7c_data.keys())[-11:-1]\n",
    "    last10_bigram_logoddratio = list(task7c_data.values())[-11:-1]\n",
    "\n",
    "    plt.clf()    \n",
    "    fig, (top10, last10) = plt.subplots(2, figsize=(15, 25))\n",
    "    top10.bar(top10_bigram, top10_bigram_logoddratio)\n",
    "    top10.set_xticklabels(top10_bigram, rotation=45, fontsize=15)\n",
    "    last10.bar(last10_bigram, last10_bigram_logoddratio)\n",
    "    last10.set_xticklabels(last10_bigram ,rotation=45, fontsize=15)\n",
    "\n",
    "    fig.suptitle('Top 10 bigrams and Last 10 bigrams log odds ratio', fontsize=40)\n",
    "    last10.set_xlabel('Bigrams', fontsize=30)\n",
    "    top10.set_ylabel('Log odds ratio', fontsize=20)\n",
    "    last10.set_ylabel('Log odds ratio', fontsize=20)\n",
    "    plt.savefig('task7c.png')\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
